# Content Crawler

## Get Vernacular

```js
const fs = require("fs");
const path = require("path");
const axios = require("axios");
const cheerio = require("cheerio");

/* 
javascript: (function (){
    function l(u, i) {
        var d = document;
        if (!d.getElementById(i)) {
            var s = d.createElement('script');
            s.src = u;
            s.id = i;
            d.body.appendChild(s);
        }
    } l('//ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js', 'jquery')
})();

copy($('.MsoNormal a').map(function() {
    return {
      title: String($(this).text()).trim(),
      href: $(this).attr('href')
    }
}).get());
*/

const SITE_MAP = [];

let table = [];

const main = async () => {
  for await (let { title, href } of SITE_MAP) {
    const response = await axios.get(href);
    const html = response.data;

    const $ = cheerio.load(html);

    const content = $(".paragraph").text();
    const page = {
      title: title,
      href: href,
      content: content,
    };

    table.push(page);
  }

  fs.writeFileSync(
    path.resolve(__dirname, "pages.json"),
    JSON.stringify(table, null, 2)
  );
};
main();
```

## Format Vernacular

```js
const fs = require("fs");
const path = require("path");

let table = [];

const main = async () => {
  const PAGES = fs.readFileSync(path.resolve(__dirname, "pages.json"), "utf-8");

  JSON.parse(PAGES).forEach((page, index) => {
    const { title, href, content } = page;

    const formattedContent = content
      .split(" ")
      .map((item) => {
        const trimmedItem = item.trim();

        if (trimmedItem === "") {
          return null;
        }

        return `&emsp;&emsp;${trimmedItem}`;
      })
      .filter((line) => line !== null);

    table.push({
      title,
      href,
      content: formattedContent,
    });
  });

  fs.writeFileSync(
    path.resolve(__dirname, "formatted.json"),
    JSON.stringify(table)
  );
};
main();
```

### Generate Content

```js
const fs = require("fs");
const path = require("path");

/*
 * copy($(".wikisubsectiontitle").text());
 * copy($(".ctext").text());
 */

const TITLE = "《XX》 《XXX》".split(" ");

const VERNACULAR = JSON.parse(
  fs.readFileSync(path.resolve(__dirname, "formatted.json"), "utf-8")
).map((item) => item.content.join("\n\n"));

let temp = [];
let meta = {};

const main = async () => {
  const CONTENT = fs.readFileSync(
    path.resolve(__dirname, "./volxx.txt"),
    "utf-8"
  );

  let table = Array.from({ length: TITLE.length }, () => []);
  let currentIndex = -1;
  let flag = 0;

  CONTENT.split("\n").forEach((line, index) => {
    if (line.startsWith("1 ")) {
      flag = 0;
      currentIndex++;
      table[currentIndex] = [];
    } else {
      flag++;
    }

    table[currentIndex].push(line);
  });

  TITLE.forEach((title, index) => {
    const content = table[index]
      .map((item, i) => `${i > 0 ? `\n>\n` : ""}> ${item.split(" ")[1]}`)
      .join("");
    const vernacular = VERNACULAR[index];

    temp.push({
      title,
      content,
      vernacular,
    });

    const template = `# ${title}

${content}

${vernacular}
`;

    meta[`chapter-${String(index + 1).padStart(2, "0")}`] = title;

    fs.writeFileSync(
      path.resolve(
        __dirname,
        `chapter-${String(index + 1).padStart(2, "0")}.mdx`
      ),
      template
    );
  });

  fs.writeFileSync(
    path.resolve(__dirname, "_meta.json"),
    JSON.stringify(meta, null, "\t")
  );
  fs.writeFileSync(
    path.resolve(__dirname, "volxx.json"),
    JSON.stringify(temp, null, "\t")
  );
};
main();
```
